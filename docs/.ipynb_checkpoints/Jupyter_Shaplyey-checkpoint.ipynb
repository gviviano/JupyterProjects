{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Shapley Value Analysis for Customer Satisfaction\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook implements the Shapley Value analysis to identify key drivers of customer satisfaction (or dissatisfaction) based on the methodology described in the paper \\\"Customer Satisfaction Analysis: Identification of Key Drivers\\\" by Conklin, Powaga, and Lipovetsky.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Steps:**\\n\",\n",
    "    \"1. **Setup & Configuration**: Define file paths, column names, and thresholds.\\n\",\n",
    "    \"2. **Data Preprocessing**: Load and binarize data.\\n\",\n",
    "    \"3. **Shapley Value Calculation**: Compute Shapley values for each feature.\\n\",\n",
    "    \"4. **Key Driver Identification**: Determine the optimal set of key dissatisfiers.\\n\",\n",
    "    \"5. **Results**: View the Shapley values and the identified key drivers.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Import Libraries\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import itertools\\n\",\n",
    "    \"import math\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Define Helper Functions\\n\",\n",
    "    \"\\n\",\n",
    "    \"These functions are the core logic for preprocessing, calculating coalition values, Shapley values, and determining key drivers.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def preprocess_data(filepath, overall_satisfaction_col, feature_cols, \\n\",\n",
    "    \"                    dissatisfaction_threshold, failure_threshold_map,\\n\",\n",
    "    \"                    overall_score_higher_is_better=True, \\n\",\n",
    "    \"                    feature_score_higher_is_better=True):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Loads and preprocesses the data.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    df = pd.read_csv(filepath)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Binarize overall satisfaction\\n\",\n",
    "    \"    binarized_overall_col = f\\\"{overall_satisfaction_col}_Dissatisfied\\\"\\n\",\n",
    "    \"    if overall_score_higher_is_better:\\n\",\n",
    "    \"        df[binarized_overall_col] = (df[overall_satisfaction_col] <= dissatisfaction_threshold).astype(int)\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        df[binarized_overall_col] = (df[overall_satisfaction_col] >= dissatisfaction_threshold).astype(int)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Binarize feature columns\\n\",\n",
    "    \"    binarized_feature_cols = []\\n\",\n",
    "    \"    for col in feature_cols:\\n\",\n",
    "    \"        bin_col_name = f\\\"{col}_Failed\\\"\\n\",\n",
    "    \"        threshold_info = failure_threshold_map.get(col)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        current_feature_higher_is_better = feature_score_higher_is_better # Default\\n\",\n",
    "    \"        current_failure_threshold = None\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if isinstance(threshold_info, tuple): # (threshold, specific_higher_is_better)\\n\",\n",
    "    \"            current_failure_threshold = threshold_info[0]\\n\",\n",
    "    \"            current_feature_higher_is_better = threshold_info[1]\\n\",\n",
    "    \"        elif threshold_info is not None: # Just threshold, use global feature_score_higher_is_better\\n\",\n",
    "    \"            current_failure_threshold = threshold_info\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            raise ValueError(f\\\"Failure threshold not defined for feature: {col}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if current_feature_higher_is_better:\\n\",\n",
    "    \"            df[bin_col_name] = (df[col] <= current_failure_threshold).astype(int)\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            df[bin_col_name] = (df[col] >= current_failure_threshold).astype(int)\\n\",\n",
    "    \"        binarized_feature_cols.append(bin_col_name)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    return df, binarized_overall_col, binarized_feature_cols\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def get_value_of_coalition(df, coalition_bin_feature_cols, binarized_overall_col):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Calculates the value v(M) = Reach_M - Noise_M for a given coalition M.\\n\",\n",
    "    \"    M is represented by a list of binarized feature column names.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    if not coalition_bin_feature_cols: # Empty coalition\\n\",\n",
    "    \"        return 0.0\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Mask for rows where at least one feature in the coalition has \\\"Failed\\\" (is 1)\\n\",\n",
    "    \"    failed_on_any_in_coalition_mask = df[coalition_bin_feature_cols].any(axis=1)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    df_dissatisfied = df[df[binarized_overall_col] == 1]\\n\",\n",
    "    \"    df_not_dissatisfied = df[df[binarized_overall_col] == 0]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    num_total_dissatisfied = len(df_dissatisfied)\\n\",\n",
    "    \"    num_total_not_dissatisfied = len(df_not_dissatisfied)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if num_total_dissatisfied == 0 and num_total_not_dissatisfied == 0:\\n\",\n",
    "    \"        print(\\\"Warning: No data points found for calculating coalition value.\\\")\\n\",\n",
    "    \"        return 0.0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if num_total_dissatisfied > 0:\\n\",\n",
    "    \"        num_failed_and_dissatisfied = df_dissatisfied[failed_on_any_in_coalition_mask[df_dissatisfied.index]].shape[0]\\n\",\n",
    "    \"        reach_M = num_failed_and_dissatisfied / num_total_dissatisfied\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        reach_M = 0.0 \\n\",\n",
    "    \"\\n\",\n",
    "    \"    if num_total_not_dissatisfied > 0:\\n\",\n",
    "    \"        num_failed_and_not_dissatisfied = df_not_dissatisfied[failed_on_any_in_coalition_mask[df_not_dissatisfied.index]].shape[0]\\n\",\n",
    "    \"        noise_M = num_failed_and_not_dissatisfied / num_total_not_dissatisfied\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        noise_M = 0.0\\n\",\n",
    "    \"\\n\",\n",
    "    \"    value_M = reach_M - noise_M\\n\",\n",
    "    \"    return value_M\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def calculate_shapley_values(df, binarized_feature_cols, binarized_overall_col):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Calculates Shapley values for each feature.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    num_features = len(binarized_feature_cols)\\n\",\n",
    "    \"    feature_indices = list(range(num_features))\\n\",\n",
    "    \"    shapley_values = np.zeros(num_features)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for i in feature_indices: \\n\",\n",
    "    \"        feature_k_col_name = binarized_feature_cols[i]\\n\",\n",
    "    \"        remaining_feature_indices = [idx for idx in feature_indices if idx != i]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        for m_size in range(num_features): \\n\",\n",
    "    \"            if num_features - m_size - 1 < 0:\\n\",\n",
    "    \"                 pass \\n\",\n",
    "    \"\\n\",\n",
    "    \"            gamma_weight = (math.factorial(m_size) * math.factorial(num_features - m_size - 1)) / math.factorial(num_features)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            for M_indices_tuple in itertools.combinations(remaining_feature_indices, m_size):\\n\",\n",
    "    \"                M_cols = [binarized_feature_cols[idx] for idx in M_indices_tuple]\\n\",\n",
    "    \"                M_union_k_cols = M_cols + [feature_k_col_name]\\n\",\n",
    "    \"\\n\",\n",
    "    \"                v_M_union_k = get_value_of_coalition(df, M_union_k_cols, binarized_overall_col)\\n\",\n",
    "    \"                v_M = get_value_of_coalition(df, M_cols, binarized_overall_col)\\n\",\n",
    "    \"                \\n\",\n",
    "    \"                shapley_values[i] += gamma_weight * (v_M_union_k - v_M)\\n\",\n",
    "    \"                \\n\",\n",
    "    \"    return {binarized_feature_cols[i]: shapley_values[i] for i in range(num_features)}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def get_reach_noise_success_for_set(df, set_bin_feature_cols, binarized_overall_col):\\n\",\n",
    "    \"    \\\"\\\"\\\"Calculates Reach, Noise, and Success for a given set of (binarized) features.\\\"\\\"\\\"\\n\",\n",
    "    \"    if not set_bin_feature_cols:\\n\",\n",
    "    \"        return 0.0, 0.0, 0.0\\n\",\n",
    "    \"\\n\",\n",
    "    \"    failed_on_any_in_set_mask = df[set_bin_feature_cols].any(axis=1)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    df_dissatisfied = df[df[binarized_overall_col] == 1]\\n\",\n",
    "    \"    df_not_dissatisfied = df[df[binarized_overall_col] == 0]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    num_total_dissatisfied = len(df_dissatisfied)\\n\",\n",
    "    \"    num_total_not_dissatisfied = len(df_not_dissatisfied)\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if num_total_dissatisfied == 0 and num_total_not_dissatisfied == 0:\\n\",\n",
    "    \"        return 0.0, 0.0, 0.0\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if num_total_dissatisfied > 0:\\n\",\n",
    "    \"        num_failed_and_dissatisfied = df_dissatisfied[failed_on_any_in_set_mask[df_dissatisfied.index]].shape[0]\\n\",\n",
    "    \"        reach = num_failed_and_dissatisfied / num_total_dissatisfied\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        reach = 0.0\\n\",\n",
    "    \"\\n\",\n",
    "    \"    if num_total_not_dissatisfied > 0:\\n\",\n",
    "    \"        num_failed_and_not_dissatisfied = df_not_dissatisfied[failed_on_any_in_set_mask[df_not_dissatisfied.index]].shape[0]\\n\",\n",
    "    \"        noise = num_failed_and_not_dissatisfied / num_total_not_dissatisfied\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        noise = 0.0\\n\",\n",
    "    \"        \\n\",\n",
    "    \"    success = reach - noise\\n\",\n",
    "    \"    return reach, noise, success\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def determine_key_drivers(df, binarized_feature_cols, binarized_overall_col, shapley_values_dict):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Determines the key dissatisfiers based on Shapley values and the Success metric.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    sorted_features = sorted(shapley_values_dict.items(), key=lambda item: item[1], reverse=True)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\n--- Determining Key Dissatisfiers (Cumulative Analysis) ---\\\")\\n\",\n",
    "    \"    print(f\\\"{'Step':<5} {'Added Feature':<30} {'Cumulative Set Size':<20} {'Reach':<10} {'Noise':<10} {'Success':<10}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    cumulative_set_cols = []\\n\",\n",
    "    \"    optimal_set_cols = []\\n\",\n",
    "    \"    max_success_achieved = -float('inf')\\n\",\n",
    "    \"    results_log = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"    for i, (feature_col, sv) in enumerate(sorted_features):\\n\",\n",
    "    \"        current_cumulative_cols_for_step = cumulative_set_cols + [feature_col]\\n\",\n",
    "    \"        reach, noise, success = get_reach_noise_success_for_set(df, current_cumulative_cols_for_step, binarized_overall_col)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        results_log.append({\\n\",\n",
    "    \"            'step': i + 1,\\n\",\n",
    "    \"            'added_feature': feature_col.replace('_Failed', ''),\\n\",\n",
    "    \"            'set_size': len(current_cumulative_cols_for_step),\\n\",\n",
    "    \"            'reach': reach,\\n\",\n",
    "    \"            'noise': noise,\\n\",\n",
    "    \"            'success': success\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"        print(f\\\"{i+1:<5} {feature_col.replace('_Failed', ''):<30} {len(current_cumulative_cols_for_step):<20} {reach:<10.3f} {noise:<10.3f} {success:<10.3f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"        if success >= max_success_achieved:\\n\",\n",
    "    \"            max_success_achieved = success\\n\",\n",
    "    \"            optimal_set_cols = list(current_cumulative_cols_for_step)\\n\",\n",
    "    \"            cumulative_set_cols.append(feature_col)\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(f\\\"Success decreased. Optimal set identified before adding '{feature_col.replace('_Failed', '')}'.\\\")\\n\",\n",
    "    \"            break \\n\",\n",
    "    \"            \\n\",\n",
    "    \"    return [col.replace('_Failed', '') for col in optimal_set_cols], results_log\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Configuration and Execution\\n\",\n",
    "    \"\\n\",\n",
    "    \"Modify the parameters in the next cell to match your dataset and analysis requirements.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# --- Configuration ---\\n\",\n",
    "    \"filepath = 'sample_customer_data.csv' # Replace with your actual file path\\n\",\n",
    "    \"\\n\",\n",
    "    \"overall_satisfaction_col = 'OverallSatisfaction' \\n\",\n",
    "    \"dissatisfaction_threshold = 5 \\n\",\n",
    "    \"overall_score_higher_is_better = True\\n\",\n",
    "    \"\\n\",\n",
    "    \"feature_cols = ['FeatureA', 'FeatureB', 'FeatureC', 'FeatureD']\\n\",\n",
    "    \"failure_threshold_map = {\\n\",\n",
    "    \"    'FeatureA': 3,\\n\",\n",
    "    \"    'FeatureB': 3,\\n\",\n",
    "    \"    'FeatureC': (7, False), \\n\",\n",
    "    \"    'FeatureD': 2\\n\",\n",
    "    \"}\\n\",\n",
    "    \"feature_score_higher_is_better = True \\n\",\n",
    "    \"\\n\",\n",
    "    \"# --- Create a dummy sample_customer_data.csv for testing (Optional) ---\\n\",\n",
    "    \"# You can comment this out if you have your own CSV file.\\n\",\n",
    "    \"data = {\\n\",\n",
    "    \"    'OverallSatisfaction': [2, 8, 5, 10, 3, 6, 1, 9, 4, 7, 2, 5, 8, 3, 6, 10, 1, 4, 9, 7],\\n\",\n",
    "    \"    'FeatureA':            [1, 5, 3,  4, 2, 5, 1, 4, 2, 3, 1, 3, 5, 2, 4, 5, 1, 2, 5, 3],\\n\",\n",
    "    \"    'FeatureB':            [2, 4, 2,  5, 1, 3, 2, 5, 1, 4, 2, 2, 4, 1, 3, 5, 2, 1, 5, 4],\\n\",\n",
    "    \"    'FeatureC':            [8, 3, 6,  2, 9, 4, 10,1, 7, 5, 8, 6, 2, 9, 4, 1, 10,7, 3, 5],\\n\",\n",
    "    \"    'FeatureD':            [1, 3, 1,  3, 1, 2, 1, 3, 1, 2, 1, 1, 3, 1, 2, 3, 1, 1, 3, 2] \\n\",\n",
    "    \"}\\n\",\n",
    "    \"df_sample = pd.DataFrame(data)\\n\",\n",
    "    \"df_sample.to_csv(filepath, index=False)\\n\",\n",
    "    \"print(f\\\"Created/Replaced dummy data at {filepath}\\\")\\n\",\n",
    "    \"# --- End of dummy data creation ---\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 1. Preprocess data\\n\",\n",
    "    \"df_processed, bin_overall_col, bin_feature_cols = preprocess_data(\\n\",\n",
    "    \"    filepath,\\n\",\n",
    "    \"    overall_satisfaction_col,\\n\",\n",
    "    \"    feature_cols,\\n\",\n",
    "    \"    dissatisfaction_threshold,\\n\",\n",
    "    \"    failure_threshold_map,\\n\",\n",
    "    \"    overall_score_higher_is_better,\\n\",\n",
    "    \"    feature_score_higher_is_better\\n\",\n",
    "    \")\\n\",\n",
    "    \"print(\\\"\\\\n--- Processed Data Head ---\\\")\\n\",\n",
    "    \"print(df_processed[[bin_overall_col] + bin_feature_cols].head())\\n\",\n",
    "    \"\\n\",\n",
    "    \"if df_processed[bin_overall_col].nunique() < 2:\\n\",\n",
    "    \"    print(f\\\"\\\\nWarning: The binarized overall satisfaction column '{bin_overall_col}' has only one unique value.\\\")\\n\",\n",
    "    \"    print(\\\"This will lead to Reach or Noise (or both) being undefined or zero for all coalitions.\\\")\\n\",\n",
    "    \"    print(\\\"Please check your dissatisfaction_threshold and data distribution.\\\")\\n\",\n",
    "    \"    if df_processed[df_processed[bin_overall_col] == 1].empty:\\n\",\n",
    "    \"        print(\\\"No customers are marked as 'Dissatisfied'.\\\")\\n\",\n",
    "    \"    if df_processed[df_processed[bin_overall_col] == 0].empty:\\n\",\n",
    "    \"        print(\\\"No customers are marked as 'Not Dissatisfied'.\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    # 2. Calculate Shapley values\\n\",\n",
    "    \"    print(\\\"\\\\nCalculating Shapley values... (this may take time for many features)\\\")\\n\",\n",
    "    \"    shapley_values = calculate_shapley_values(df_processed, bin_feature_cols, bin_overall_col)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\n--- Shapley Values ---\\\")\\n\",\n",
    "    \"    for feature, sv in sorted(shapley_values.items(), key=lambda item: item[1], reverse=True):\\n\",\n",
    "    \"        print(f\\\"{feature.replace('_Failed', ''):<30}: {sv:.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # 3. Determine Key Dissatisfiers\\n\",\n",
    "    \"    key_dissatisfiers, full_log = determine_key_drivers(df_processed, bin_feature_cols, bin_overall_col, shapley_values)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\n--- Final Set of Key Dissatisfiers ---\\\")\\n\",\n",
    "    \"    if key_dissatisfiers:\\n\",\n",
    "    \"        for kd in key_dissatisfiers:\\n\",\n",
    "    \"            print(f\\\"- {kd}\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"No key dissatisfiers identified based on the criteria (or no features provided).\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. How to Use and Interpret\\n\",\n",
    "    \"\\n\",\n",
    "    \"1.  **Modify Configuration**: \\n\",\n",
    "    \"    * Update `filepath` to point to your CSV data file.\\n\",\n",
    "    \"    * Set `overall_satisfaction_col` to the name of your overall satisfaction score column.\\n\",\n",
    "    \"    * Adjust `dissatisfaction_threshold` and `overall_score_higher_is_better` based on your overall satisfaction scale.\\n\",\n",
    "    \"    * List your raw feature column names in `feature_cols`.\\n\",\n",
    "    \"    * Carefully define `failure_threshold_map`. For each feature, specify the threshold that denotes a \\\"failure\\\". You can also specify if a lower score is better for a particular feature, e.g., `{'PriceComplaints': (1, False)}` might mean 1 or more complaints is a failure, and fewer complaints are better.\\n\",\n",
    "    \"    * Set `feature_score_higher_is_better` as the default for your feature scales.\\n\",\n",
    "    \"2.  **Run All Cells**: Execute the cells in order (e.g., by clicking \\\"Run All\\\" in your Jupyter environment).\\n\",\n",
    "    \"3.  **Interpret Results**:\\n\",\n",
    "    \"    * **Processed Data Head**: Shows the first few rows of your data after binarization. Check if `_Dissatisfied` and `_Failed` columns look correct.\\n\",\n",
    "    \"    * **Shapley Values**: Lists each feature and its calculated Shapley value. Higher values indicate a greater contribution to the overall \\\"Success\\\" metric (Reach - Noise), meaning the feature is more important in distinguishing dissatisfied customers.\\n\",\n",
    "    \"    * **Determining Key Dissatisfiers (Cumulative Analysis)**: This table shows the step-by-step process of adding features (ordered by Shapley value) to a potential set of key dissatisfiers. It tracks the cumulative Reach, Noise, and Success of the set at each step.\\n\",\n",
    "    \"    * **Final Set of Key Dissatisfiers**: This is the primary output. It's the set of features that, when considered together, maximized the `Success = Reach - Noise` metric. These are the features your analysis suggests are the most critical drivers of dissatisfaction.\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Important Considerations:**\\n\",\n",
    "    \"* **Computational Cost**: Calculating exact Shapley values is computationally intensive (factorial complexity with the number of features). For more than ~10-12 features, this script might become very slow. The original paper suggests sampling for larger datasets.\\n\",\n",
    "    \"* **Data Quality**: The quality of your input data and the appropriateness of your thresholds significantly impact the results.\\n\",\n",
    "    \"* **Definition of \\\"Failure\\\" and \\\"Dissatisfaction\\\"**: Carefully consider how you define these for your specific context. The thresholds directly influence the binarization and subsequent calculations.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3 (ipykernel)\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.10.12\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "a395947dd0c558f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
